#!/usr/bin/env python
# -*- coding: utf-8 -*-

# date : 311012
# date modified : 021112
# - add the multiprocessing feature
# date modified : 031112
# - add the strand conversion
# - add output_dir feature to dump the converted bed files

##################################
# Convert .GEMsam to .bed format #
##################################


# for threading jobs
import Queue
import multiprocessing

import gc
import os
import sys
import glob

# build commandline interface
import argparse
from argparse import RawTextHelpFormatter

#key:chr and value: size
dict_genome_size_hg19 = {
   'chr1': 249250621,
   'chr2': 243199373,
   'chr3': 198022430,
   'chr4': 191154276,
   'chr5': 180915260,
   'chr6': 171115067,
   'chr7': 159138663,
   'chr8': 146364022,
   'chr9': 141213431,
   'chr10': 135534747,
   'chr11': 135006516,
   'chr12': 133851895,
   'chr13': 115169878,
   'chr14': 107349540,
   'chr15': 102531392,
   'chr16': 90354753,
   'chr17': 81195210,
   'chr18': 78077248,
   'chr19': 59128983,
   'chr20': 63025520,
   'chr21': 48129895,
   'chr22': 51304566,
   'chrX': 155270560,
   'chrY': 59373566,
}

def gemSam2Bed(input_file, dict_hg19 = dict_genome_size_hg19, output_dir='.'):
   """
   convert sam from gem mapper to bed format
   """

   # remove the garbage collector during list append
   gc.disable()

   # collect the converted line in bed format into a list (!memory consumption high!)
   bedlist = []
   try:
      # start converting
      with open(input_file, 'r') as input_f:
         for line in input_f:
            items = line.split('\t')

            # skip the gem-sam's header, prefixed with @
            if items[0][0] == "@":
               continue
            else:
               chrom = items[2]
               if chrom in dict_hg19:
                  # note: sam is one-based index whereas bed is zero-based index
                  start = str(int(items[3])-1)
                  end = str(int(items[3]) + len(items[9]) - 1 )
                  strand= getStrand(int(items[1]))
                  bedlist.append("%s\t%s\t%s\t%s\n" % (chrom, start, end, strand))

   #catch possible errors
   except IndexError:
      sys.stderr.write("Check if your file is properly formatted, field separator is a tab")
   except:
      sys.stderr.write('file error:%s'%(input_file.name))
      raise
      
   gc.enable()

   #finally output the file
   if not os.path.exists(output_dir):
      os.makedirs(output_dir)

   head, tail = os.path.split(input_file)
   base = os.path.splitext(tail)[0]
   output_fname="%s.bed" %(base)
   output_file = str(os.path.join(output_dir, output_fname))

   with open(output_file, 'w') as output_f:
      for line in bedlist:
         output_f.write(line)

def getStrand(samFlag):
   """
   strand is encoded in hexadecimal,
   0x10 means 16 and the strand is -
   """
   strand = "+"
   if (samFlag & (0x10)):
      strand = "-"      
   return strand


class bedThread(multiprocessing.Process):
   """
   convert into bed in multiple threads
   """

   def __init__(self, lock, queue, output_dir):
      self.lock = lock
      self.queue = queue
      self.output_dir = output_dir
      multiprocessing.Process.__init__(self)

   def run(self):
      while True:
         self.lock.acquire()
         try:
            data = queue.get_nowait()
         except Queue.Empty:
            return
         finally:
            self.lock.release()
         gemSam2Bed(input_file=data, output_dir=self.output_dir)
         self.queue.task_done()



if __name__ == "__main__":
   parser = argparse.ArgumentParser(
      prog = 'gemSam2Bed.py',
      description = """Convert sam format generated by gem-1-sam into bed,
      - n : number of cores for threading
      NOTE: THIS conversion would consume large amount of your memory,
      as the file processed into memory to gain speed during threading
      DO NOT RUN if you have only small memory
      """,
      formatter_class=RawTextHelpFormatter
   )
   parser.add_argument(
       'input_file',
       metavar = 'f',
       type = str,
       nargs = '?',
       default = sys.stdin,
       help = 'file to process'
   )
   parser.add_argument(
      '-n',
      '--n-threads',
      metavar = 'n',
      type = int,
      nargs = '?',
      default = 1,
      help = 'number of threads to run in parallel'
   )
   parser.add_argument(
      '-od',
      '--output_dir',
      metavar = 'od',
      type = str,
      nargs = '?',
      default = '.',
      help = 'directory for the output file'
   )


   args = parser.parse_args()

   # converting into bed with threads
   lock = multiprocessing.Lock()
   queue = multiprocessing.JoinableQueue(-1)
   manager = multiprocessing.Manager()

   for file_f in glob.glob(args.input_file):
      queue.put_nowait(file_f)
   
   processes = [bedThread(lock, queue, args.output_dir) for i in range(args.n_threads)]
   for process in processes:
      process.start()
   queue.join()
